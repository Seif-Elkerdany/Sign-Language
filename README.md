This is my first computer vision project!

  - First file (Collecting_trainingData) is to collect data from folder that have all the images of hand gestures and normalizing all the hand landmarks then collecting every image and its label in a csv file.
  - Second file (ML_model) is the model I trained with the csv file to use this model to predict the labels I used MLPClassifier from neural_network module in scikit-learn.
  - Third file (SignLanguage_apk) is the main program that uses real time camera to predict each label in the sign language.
